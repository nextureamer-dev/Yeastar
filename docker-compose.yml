services:
  ai-transcription:
    image: nvcr.io/nvidia/pytorch:25.11-py3
    container_name: yeastar-ai
    network_mode: host
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - TRITON_PTXAS_PATH=/usr/local/cuda/bin/ptxas
      - HF_HOME=/workspace/huggingface
      # Optional: HuggingFace token for speaker diarization (who said what)
      # To enable: 1) Get token from https://huggingface.co/settings/tokens
      #            2) Accept license at https://huggingface.co/pyannote/speaker-diarization-3.1
      #            3) Add: pip install pyannote-audio soundfile (in command below)
      #            4) Set HF_TOKEN=your_token_here
      - HF_TOKEN=${HF_TOKEN:-}
    volumes:
      - ./backend:/workspace/backend
      - ./ai_models:/workspace/models
      - huggingface_cache:/workspace/huggingface
    working_dir: /workspace
    command: >
      bash -c "apt-get update && apt-get install -y ffmpeg libsndfile1 &&
      pip install faster-whisper httpx fastapi uvicorn sqlalchemy pydantic-settings python-jose passlib bcrypt websockets aiofiles transformers accelerate &&
      cd /workspace/backend && python -m uvicorn app.main:app --host 0.0.0.0 --port 8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  huggingface_cache:
